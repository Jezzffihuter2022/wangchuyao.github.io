---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

## Publication

**[1] Panacea or Pandora's Box: Diverse Governance Strategies to Conspiracy Theories and Their Consequences in China**  
Co-first and corresponding author, *Humanities and Social Sciences Communications*, 2025; IF = 3.6, SSCI Q1  
[Full text](https://www.nature.com/articles/s41599-024-04350-1) published on nature.com (Nature Portfolio)

Abstract 

This study examines the Chinese government’s strategies for managing conspiracy theories (CTs) on social media. While previous research has primarily considered how authoritarian regimes disseminate CTs for political purposes and has often viewed the public as fully receptive to propaganda and easily manipulated, our research explores a broader spectrum of state strategies including propagation, tolerance, and partial rebuttal. Based on social network analysis, topic modeling, and qualitative analysis of 46,387 Weibo posts from 3 cases, we argue that the Chinese government’s manipulation of CTs is multifaceted and carries significant audience costs. Our findings indicate that state-led CTs can indeed mobilize public opinion, but they also risk expanding beyond state control, which can lead to unintended consequences that may undermine state interests and limit policy flexibility. This research contributes to our understanding of the tactical and operational complexities authoritarian regimes face when leveraging CTs, while highlighting the intricate balance between state control and public agency.

## Under Review

**[2] AI Labeling Reduces the Perceived Accuracy of Online Content but Has Limited Broader Effects** (Job Market Paper) 
First and corresponding author; under review at *Nature Communications*; IF = 15.7, SCI Q1  
[Full text at arXiv](https://arxiv.org/your-link)

Abstract 

Explicit labeling of online content produced by artificial intelligence (AI) is a widely discussed policy for ensuring transparency and promoting public confidence. Yet little is known about the scope of AI labeling effects on public assessments of labeled content. We contribute new evidence on this question from a survey experiment using a high-quality nationally representative probability sample (\emph{n} = 3,861). First, we demonstrate that explicit AI labeling of a news article about a proposed public policy reduces its perceived accuracy. Second, we test whether there are spillover effects in terms of policy interest, policy support, and general concerns about online misinformation. We find that AI labeling reduces interest in the policy, but neither influences support for the policy nor triggers general concerns about online misinformation. We further find that increasing the salience of AI use reduces the negative impact of AI labeling on perceived accuracy, while one-sided versus two-sided framing of the policy has no moderating effect. Overall, our findings suggest that the effects of algorithm aversion induced by AI labeling of online content are limited in scope.

**[3] Bureaucrat-Expert Collaboration in Large Language Model Adoption**  
Second author; under review at *Technology in Society*; IF = 12.5, SSCI Q1
- Revealed priority conflicts between bureaucratic control and professional logics in LLM deployment
- Analyzed how cross-sector negotiations shaped model choice and data security

**[4] Framing Trump in Chinese and US News: A Computational Visual Analysis**  
Sole author; under review at *International Journal of Press/Politics*; IF = 4.3, SSCI Q1  
[Abstract at SSRN](your-ssrn-link)
- Applied machine learning on 257,056 images to reveal visual framing bias
- Found Chinese media portray Trump as more negative and less trustworthy than US media

**[5] Governing Online Political Discourse: A Social Simulation of Self-Censorship using LLM**  
Second and corresponding author; manuscript for *PNAS Nexus*; IF = 3.8
- Applied LLM-based annotation on 343,764 tweets with counterfactual simulation
- Demonstrated how regulatory intervention induces online self-censorship

## Working Papers

**[6] How LLM Sycophancy Shapes Individuals' Perceived Social Norms**  
First author; for *Nature Human Behaviour*; IF = 15.9, SSCI Q1
- Investigated how LLMs' sycophancy produces biased information
- Designed personalized human-AI conversational survey experiment (n=3,100)

**[7] How AI Labeling Affects Policy Support in Social Networks**  
Second and corresponding author; for *Political Analysis*; IF = 5.4, SSCI Q1  
[Extended abstract at SSRN](your-link)

**[8] Advancing Heterogeneous Treatment Effect Analysis**  
Sole author; for *Political Science Research and Methods*; IF = 2.6, SSCI Q1
