---
layout: archive
title: "Research"
permalink: /publications/
author_profile: true
---

Why do well-intended strategies in political communication sometimes backfire, eroding trust or distorting perceptions? At the intersection of AI governance, political communication, and computational social science, I examine how credibility cues, algorithmic systems, and sociotechnical infrastructures shape public opinion on digital platforms—often in unintended ways. To investigate these dynamics, I employ a mixed-methods approach combining survey experiments, computational text and image analysis, and case studies.

My research program has produced 8 papers with 5 as first author and 6 as corresponding author. These include publication in *Humanities and Social Sciences Communications*, manuscripts under review at *Nature Communications*, *Technology in Society*, *International Journal of Press/Politics*, and projects targeting *Nature Human Behaviour* and *Political Analysis*. My papers are accepted at top conferences across disciplines, namely APSA, ICA, ASA, and IC2S2. My working papers are supported by competitive grants from LSE, OpenAI, and Google.

## Publication

**[1] Panacea or Pandora's Box: Diverse Governance Strategies to Conspiracy Theories and Their Consequences in China** 

Co-first and corresponding author, *Humanities and Social Sciences Communications*, 2025; IF = 3.6, SSCI Q1  
Published on [nature.com](https://www.nature.com/articles/s41599-024-04350-1) (Nature Portfolio); highlighted by LSE DSI on [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7338216361464127490/), [X](https://x.com/lsedatascience/status/1932453471413760431?s=46), and official newsletter

- Analyzed authoritarian governance of conspiracy theories (CTs) via propagation, tolerance, and rebuttal 
- Combined qualitative case analysis, social network analysis, and topic modeling of 46,387 Weibo posts
- Found that diverse CT governance strategies mobilize public opinion but risk loss of control and backlash

## Under Review

**[2] AI Labeling Reduces the Perceived Accuracy of Online Content but Has Limited Broader Effects** (Job Market Paper) 

First and corresponding author; under review at *Nature Communications*; IF = 15.7, SCI Q1  
Full text at [arXiv](https://arxiv.org/pdf/2506.16202)

Abstract 

Explicit labeling of online content produced by artificial intelligence (AI) is a widely discussed policy for ensuring transparency and promoting public confidence. Yet little is known about the scope of AI labeling effects on public assessments of labeled content. We contribute new evidence on this question from a survey experiment using a high-quality nationally representative probability sample (n = 3,861). First, we demonstrate that explicit AI labeling of a news article about a proposed public policy reduces its perceived accuracy. Second, we test whether there are spillover effects in terms of policy interest, policy support, and general concerns about online misinformation. We find that AI labeling reduces interest in the policy, but neither influences support for the policy nor triggers general concerns about online misinformation. We further find that increasing the salience of AI use reduces the negative impact of AI labeling on perceived accuracy, while one-sided versus two-sided framing of the policy has no moderating effect. Overall, our findings suggest that the effects of algorithm aversion induced by AI labeling of online content are limited in scope.

**[3] Bureaucrat-Expert Collaboration in Large Language Model Adoption: An Institutional Logic Perspective on China’s Public Sector**  
Second author; under review at *Technology in Society*; IF = 12.5, SSCI Q1
- Revealed priority conflicts between bureaucratic control and professional logics in LLM deployment
- Analyzed how cross-sector negotiations shaped model choice and data security

**[4] Framing Trump in Chinese and US News: A Computational Visual Analysis**  
Sole author; under review at *International Journal of Press/Politics*; IF = 4.3, SSCI Q1  
Abstract at [SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5319923)
- Applied machine learning on 257,056 images to reveal visual framing bias
- Found Chinese media portray Trump as more negative and less trustworthy than US media

## Working Papers

**[5] How LLM Sycophancy Shapes Individuals' Perceived Social Norms and Sways Policy Attitute**  
First author; for *Nature Human Behaviour*; IF = 15.9, SSCI Q1
- Investigated how LLMs' sycophancy produces biased information
- Designed personalized human-AI conversational survey experiment (n=3,100)

**[6] Governing Online Political Discourse: A Social Simulation of Self-Censorship using Large Langauge Models**  
Second and corresponding author; manuscript for *PNAS Nexus*; IF = 3.8
- Applied LLM-based annotation on 343,764 tweets with counterfactual simulation
- Demonstrated how regulatory intervention induces online self-censorship

**[7] How AI Labeling Affects Policy Support in Social Networks: LLM-powered Simulation and Survey Experiment**  
Second and corresponding author; for *Political Analysis*; IF = 5.4, SSCI Q1  
Extended abstract at [SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5320375)

**[8] Advancing Heterogeneous Treatment Effect Analysis**  
Sole author; for *Political Science Research and Methods*; IF = 2.6, SSCI Q1
